{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jupyter Notebook Viewer](https://nbviewer.jupyter.org/github/ageron/handson-ml/blob/master/tools_pandas.ipynb)\n",
    "\n",
    "- Pandas is a package for data manipulation and analysis in Python. The name Pandas is derived from the econometrics term Panel Data. Pandas incorporates two additional data structures into Python, namely Pandas Series and Pandas DataFrame. These data structures allow us to work with labeled and relational data in an easy and intuitive manner.\n",
    "- Pandas Series and DataFrames are designed for fast data analysis and manipulation, as well as being flexible and easy to use. Below are just a few features that makes Pandas an excellent package for data analysis:\n",
    "    - Allows the use of labels for rows and columns\n",
    "    - Can calculate rolling statistics on time series data\n",
    "    - Easy handling of NaN values\n",
    "    - Is able to load data of different formats into DataFrames\n",
    "    - Can join and merge different datasets together\n",
    "    - It integrates with NumPy and Matplotlib\n",
    "- Documentation: [https://pandas.pydata.org/pandas-docs/stable/](https://pandas.pydata.org/pandas-docs/stable/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series\n",
    "1D array-like object that can hold many data types. One of the main differences between Pandas Series and NumPy ndarrays is that you can assign an index label to each element in the Pandas Series. Another big difference is that Pandas Series can hold data of different data types.\n",
    "\n",
    "pd.Series(data, index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "groceries = pd.Series(data = [30, 6, 'Yes', 'No'], index = ['eggs', 'apples', 'milk', 'bread'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shape, size, values, index, ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groceries has shape: (3,)\n",
      "Groceries has dimension: 1\n",
      "Groceries has a total of 3 elements\n",
      "The data in Groceries is: [2 'Yes' 'No']\n",
      "The index of Groceries is: Index(['eggs', 'milk', 'bread'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('Groceries has shape:', groceries.shape)\n",
    "print('Groceries has dimension:', groceries.ndim)\n",
    "print('Groceries has a total of', groceries.size, 'elements')\n",
    "print('The data in Groceries is:', groceries.values)\n",
    "print('The index of Groceries is:', groceries.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check whether an index label exists in Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether an index label exists in Series\n",
    "x = 'bananas' in groceries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'groceries' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bde265fda797>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# using index labels:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# single index label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'How many eggs do we need to buy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroceries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eggs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# access multiple index labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Do we need milk and bread:\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroceries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'milk'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bread'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'groceries' is not defined"
     ]
    }
   ],
   "source": [
    "# Accessing Elements\n",
    "# using index labels:\n",
    "# single index label\n",
    "print('How many eggs do we need to buy:', groceries['eggs'])\n",
    "# access multiple index labels\n",
    "print('Do we need milk and bread:\\n', groceries[['milk', 'bread']]) \n",
    "# use loc to access multiple index labels\n",
    "print('How many eggs and apples do we need to buy:\\n', groceries.loc[['eggs', 'apples']]) \n",
    "\n",
    "# access elements in Groceries using numerical indices:\n",
    "# use multiple numerical indices\n",
    "print('How many eggs and apples do we need to buy:\\n',  groceries[[0, 1]]) \n",
    "# use a negative numerical index\n",
    "print('Do we need bread:\\n', groceries[[-1]]) \n",
    "# use a single numerical index\n",
    "print('How many eggs do we need to buy:', groceries[0]) \n",
    "# use iloc (stands for integer location) to access multiple numerical indices\n",
    "print('Do we need milk and bread:\\n', groceries.iloc[[2, 3]])\n",
    "# Since we can access elements in various ways, in order to remove\n",
    "# any ambiguity to whether we are referring to an index label\n",
    "# or numerical index, Pandas Series have two attributes,\n",
    "# .loc and .iloc to explicitly state what we mean. The attribute\n",
    "# .loc stands for location and it is used to explicitly state that\n",
    "# we are using a labeled index. Similarly, the attribute .iloc stands\n",
    "# for integer location and it is used to explicitly state that we are\n",
    "# using a numerical index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time_light' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-0a8592ba7e52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# access using Boolean Indexes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtime_light\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtime_light\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'time_light' is not defined"
     ]
    }
   ],
   "source": [
    "# access using Boolean Indexes\n",
    "time_light[time_light<40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Elements\n",
    "groceries['eggs'] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete Elements\n",
    "# doesn't change the original Series being modified\n",
    "groceries.drop('apples')\n",
    "# delete items from Series in place by setting keyword inplace to True\n",
    "groceries.drop('apples', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arithmetic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "apples     20\n",
       "oranges    12\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Arithmetic Operations\n",
    "# we can perform element-wise arithmetic operations on Pandas Series\n",
    "fruits = pd.Series(data = [10, 6, 3,], index = ['apples', 'oranges', 'bananas'])\n",
    "fruits + 2 # Adds 2 to all elements in the series\n",
    "fruits - 2\n",
    "fruits * 2\n",
    "fruits / 2\n",
    "# apply mathematical functions from NumPy to all elements of a Series\n",
    "np.exp(fruits)\n",
    "np.sqrt(fruits)\n",
    "np.power(fruits,2)\n",
    "# only apply arithmetic operations on selected items in Series\n",
    "fruits['bananas'] + 2\n",
    "fruits.iloc[0] - 2\n",
    "fruits[['apples', 'oranges']] * 2\n",
    "# you can apply arithmetic operations on a Series of mixed data\n",
    "# type provided that the arithmetic operation is defined for all\n",
    "# data types in the Series, otherwise you will get an error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe\n",
    "Pandas DataFrames are two-dimensional data structures with labeled rows and columns, that can hold many data types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-1e510f46d5af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# understanding axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# sums “down” the 0 axis (rows)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# equivalent (since axis=0 is the default)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# understanding axes\n",
    "df.sum()       \n",
    "# sums “down” the 0 axis (rows)\n",
    "df.sum(axis=0) \n",
    "# equivalent (since axis=0 is the default)\n",
    "df.sum(axis=1) \n",
    "# sums “across” the 1 axis (columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data into DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'marauders_map.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-eec629b6a048>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Loading Data into DF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'marauders_map.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# limit which rows are read when reading in a file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'df.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'marauders_map.csv'"
     ]
    }
   ],
   "source": [
    "# Loading Data into DF\n",
    "df = pd.read_csv('marauders_map.csv')\n",
    "\n",
    "# limit which rows are read when reading in a file\n",
    "pd.read_csv('df.csv', nrows=10)        \n",
    "# only read first 10 rows\n",
    "\n",
    "pd.read_csv('df.csv', skiprows=[1, 2]) \n",
    "# skip the first two rows of data\n",
    "\n",
    "# randomly sample a DataFrame\n",
    "train = df.sample(frac=0.75, random_column_y=1) \n",
    "# will contain 75% of the rows\n",
    "\n",
    "test = df[~df.index.isin(train.index)] \n",
    "# will contain the other 25%\n",
    "\n",
    "# change the maximum number of rows and columns printed (‘None’ means unlimited)\n",
    "pd.set_option('max_rows', None) \n",
    "# default is 60 rows\n",
    "\n",
    "pd.set_option('max_columns', None) \n",
    "# default is 20 columns\n",
    "print (df)\n",
    "\n",
    "# reset options to defaults\n",
    "pd.reset_option('max_rows')\n",
    "pd.reset_option('max_columns')\n",
    "\n",
    "# change the options temporarily (settings are restored when you exit the ‘with’ block)\n",
    "with pd.option_context('max_rows', None, 'max_columns', None):\n",
    "    print (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame manually from a dictionary of Pandas Series\n",
    "\n",
    "# create a dictionary of Pandas Series \n",
    "items = {'Bob' : pd.Series(data = [245, 25, 55], index = ['bike', 'pants', 'watch']),\n",
    "         'Alice' : pd.Series(data = [40, 110, 500, 45], index = ['book', 'glasses', 'bike', 'pants'])}\n",
    "\n",
    "# print the type of items to see that it is a dictionary\n",
    "print(type(items)) # class 'dict'\n",
    "\n",
    "# create a Pandas DataFrame by passing it a dictionary of Series\n",
    "shopping_carts = pd.DataFrame(items)\n",
    "\n",
    "# create a DataFrame that only has a subset of the data/columns\n",
    "bob_shopping_cart = pd.DataFrame(items, columns=['Bob'])\n",
    "\n",
    "# create a DataFrame that only has selected keys\n",
    "sel_shopping_cart = pd.DataFrame(items, index = ['pants', 'book'])\n",
    "\n",
    "# combine both of the above - selected keys for selected columns\n",
    "alice_sel_shopping_cart = pd.DataFrame(items, index = ['glasses', 'bike'], columns = ['Alice'])\n",
    "\n",
    "# create DataFrames from a dictionary of lists (arrays)\n",
    "# In this case, however, all the lists (arrays) in the dictionary must be of the same length\n",
    "\n",
    "# create a dictionary of lists (arrays)\n",
    "data = {'Integers' : [1,2,3],\n",
    "        'Floats' : [4.5, 8.2, 9.6]}\n",
    "\n",
    "# create a DataFrame \n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# create a DataFrame and provide the row index\n",
    "df = pd.DataFrame(data, index = ['label 1', 'label 2', 'label 3'])\n",
    "\n",
    "# create DataFrames from a list of Python dictionaries\n",
    "# create a list of Python dictionaries\n",
    "items2 = [{'bikes': 20, 'pants': 30, 'watches': 35}, \n",
    "          {'watches': 10, 'glasses': 50, 'bikes': 15, 'pants':5}]\n",
    "\n",
    "# create a DataFrame \n",
    "store_items = pd.DataFrame(items2)\n",
    "\n",
    "# create a DataFrame and provide the row index\n",
    "store_items = pd.DataFrame(items2, index = ['store 1', 'store 2'])\n",
    "\n",
    "print('shopping_carts has shape:', shopping_carts.shape)\n",
    "print('shopping_carts has dimension:', shopping_carts.ndim)\n",
    "print('shopping_carts has a total of:', shopping_carts.size, 'elements')\n",
    "print()\n",
    "print('The data in shopping_carts is:\\n', shopping_carts.values)\n",
    "print()\n",
    "print('The row index in shopping_carts is:', shopping_carts.index)\n",
    "print()\n",
    "print('The column index in shopping_carts is:', shopping_carts.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create df from Series, dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-2aa3a293de2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Great Expectations'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Of Mice and Men'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Romeo and Juliet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'The Time Machine'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Alice in Wonderland'\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mauthors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Charles Dickens'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'John Steinbeck'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'William Shakespeare'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' H. G. Wells'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Lewis Carroll'\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0muser_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m2.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0muser_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m5.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0muser_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Create dictionary from a bunch of Series/data\n",
    "books = pd.Series(data = ['Great Expectations', 'Of Mice and Men', 'Romeo and Juliet', 'The Time Machine', 'Alice in Wonderland' ])\n",
    "authors = pd.Series(data = ['Charles Dickens', 'John Steinbeck', 'William Shakespeare', ' H. G. Wells', 'Lewis Carroll' ])\n",
    "user_1 = pd.Series(data = [3.2, np.nan ,2.5])\n",
    "user_2 = pd.Series(data = [5., 1.3, 4.0, 3.8])\n",
    "user_3 = pd.Series(data = [2.0, 2.3, np.nan, 4])\n",
    "user_4 = pd.Series(data = [4, 3.5, 4, 5, 4.2])\n",
    "\n",
    "# Create a dictionary with the data given above\n",
    "a_dict = {'Author':authors,'Book Title':books,'User 1':user_1, 'User 2':user_2, 'User 3':user_3, 'User 4':user_4}\n",
    "\n",
    "# Use the dictionary to create a Pandas DataFrame\n",
    "book_ratings = pd.DataFrame(a_dict)\n",
    "book_ratings[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy array (remove the column names, get just the values to convert it into a numpy array)\n",
    "book_ratings_numpy = book_ratings.values\n",
    "book_ratings_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### create a DataFrame from a dictionary\n",
    "pd.DataFrame({‘column_x’:[‘value_x1’, ‘value_x2’, ‘value_x3’], ‘column_y’:[‘value_y1’, ‘value_y2’, ‘value_y3’]})\n",
    "\n",
    "#### create a DataFrame from a list of lists\n",
    "pd.DataFrame([[‘value_x1’, ‘value_y1’], [‘value_x2’, ‘value_y2’], [‘value_x3’, ‘value_y3’]], columns=[‘column_x’, ‘column_y’])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'store_items' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-2fec24e184ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Access Elements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'How many bikes are in each store:\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstore_items\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bikes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'How many bikes and pants are in each store:\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstore_items\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bikes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pants'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'store_items' is not defined"
     ]
    }
   ],
   "source": [
    "# Access Elements\n",
    "print()\n",
    "print('How many bikes are in each store:\\n', store_items[['bikes']])\n",
    "print()\n",
    "print('How many bikes and pants are in each store:\\n', store_items[['bikes', 'pants']])\n",
    "print()\n",
    "print('What items are in Store 1:\\n', store_items.loc[['store 1']])\n",
    "print()\n",
    "print('How many bikes are in Store 2:', store_items['bikes']['store 2'])\n",
    "# when accessing individual elements in a DataFrame, the labels\n",
    "# should always be provided with the column label first,\n",
    "# i.e. in the form dataframe[column][row]\n",
    "# store_items for reference:\n",
    "#          bikes\tglasses\tpants\twatches\n",
    "# store 1\t    20\t   NaN\t   30\t     35\n",
    "# store 2\t    15\t  50.0\t    5\t     10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify Elements\n",
    "# Add new column (adds it to the end of the df)\n",
    "store_items['shirts'] = [15,2]\n",
    "\n",
    "# New column via artihmetic operations b/w columns\n",
    "store_items['suits'] = store_items['pants'] + store_items['shirts']\n",
    "\n",
    "# Add new row\n",
    "\n",
    "# To add rows to our df, create a new df then append it to the original df\n",
    "# create a dictionary from a list of Python dictionaries\n",
    "new_items = [{'bikes': 20, 'pants': 30, 'watches': 35, 'glasses': 4}]\n",
    "\n",
    "# create new DataFrame with the new_items and provide and index labeled store 3\n",
    "new_store = pd.DataFrame(new_items, index = ['store 3'])\n",
    "\n",
    "# append store 3 to our store_items DataFrame\n",
    "store_items = store_items.append(new_store)\n",
    "\n",
    "# insert a new column with label shoes right before the column with numerical index 4\n",
    "store_items.insert(4, 'shoes', [8,5,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# Delete Element\n",
    "\n",
    "# .pop() method only allows us to delete columns, while the .drop()\n",
    "# method can be used to delete both rows and columns by use of the axis keyword\n",
    "\n",
    "# remove the new watches column\n",
    "store_items.pop('new watches')\n",
    "\n",
    "# remove the watches and shoes columns\n",
    "store_items = store_items.drop(['watches', 'shoes'], axis = 1)\n",
    "\n",
    "# remove the store 2 and store 1 rows\n",
    "store_items = store_items.drop(['store 2', 'store 1'], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename the row and column labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the row and column labels\n",
    "# change the column label\n",
    "store_items = store_items.rename(columns = {'bikes': 'hats'})\n",
    "# change the row label\n",
    "store_items = store_items.rename(index = {'store 3': 'last store'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the index to be one of the columns in the DataFrame\n",
    "store_items = store_items.set_index('pants')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with NaN values (missing data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with NaN values (missing data)\n",
    "\n",
    "# create a list of Python dictionaries\n",
    "items2 = [{'bikes': 20, 'pants': 30, 'watches': 35, 'shirts': 15, 'shoes':8, 'suits':45},\n",
    "{'watches': 10, 'glasses': 50, 'bikes': 15, 'pants':5, 'shirts': 2, 'shoes':5, 'suits':7},\n",
    "{'bikes': 20, 'pants': 30, 'watches': 35, 'glasses': 4, 'shoes':10}]\n",
    "\n",
    "# We create a DataFrame and provide the row index\n",
    "store_items = pd.DataFrame(items2, index = ['store 1', 'store 2', 'store 3'])\n",
    "\n",
    "# check if we have any NaN values in our dataset\n",
    "# .any() performs an or operation. If any of the values along the\n",
    "# specified axis is True, this will return True.\n",
    "df.isnull().any()\n",
    "'''\n",
    "Date   False\n",
    "Open   True\n",
    "High   False\n",
    "Low    False\n",
    "Close  False\n",
    "Volume False\n",
    "dtype: bool\n",
    "'''\n",
    "\n",
    "# count the number of NaN values in DataFrame\n",
    "x =  store_items.isnull().sum().sum()\n",
    "# count the number of non-NaN values in DataFrame\n",
    "x = store_items.count()\n",
    "\n",
    "# remove rows or columns from our DataFrame that contain any NaN values\n",
    "\n",
    "# drop any rows with NaN values\n",
    "store_items.dropna(axis = 0)\n",
    "\n",
    "# drop any columns with NaN values\n",
    "store_items.dropna(axis = 1)\n",
    "\n",
    "# the original DataFrame is not modified by default\n",
    "# to remove missing values from original df, use inplace = True\n",
    "store_items.dropna(axis = 0, inplace = True)\n",
    "\n",
    "# replace all NaN values with 0\n",
    "store_items.fillna(0)\n",
    "\n",
    "# forward filling: replace NaN values with previous values in the df,\n",
    "# this is known as . When replacing NaN values with forward filling,\n",
    "# we can use previous values taken from columns or rows.\n",
    "# replace NaN values with the previous value in the column\n",
    "store_items.fillna(method = 'ffill', axis = 0)\n",
    "\n",
    "# backward filling: replace the NaN values with the values that\n",
    "# go after them in the DataFrame\n",
    "# replace NaN values with the next value in the row\n",
    "store_items.fillna(method = 'backfill', axis = 1)\n",
    "\n",
    "# replace NaN values by using linear interpolation using column values\n",
    "store_items.interpolate(method = 'linear', axis = 0)\n",
    "\n",
    "# the original DataFrame is not modified. replace the NaN values\n",
    "# in place by setting inplace = True inside function\n",
    "store_items.fillna(method = 'ffill', axis = 0, inplace = True)\n",
    "store_items.interpolate(method = 'linear', axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### head, tail, describe, max, memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df.tail()\n",
    "df.describe()\n",
    "# prints max value in each column\n",
    "df.max()\n",
    "\n",
    "# display the memory usage of a DataFrame\n",
    "# total usage\n",
    "df.info()\n",
    "# usage by column\n",
    "df.memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the correlation between different columns\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# Groupby\n",
    "data.groupby(['Year'])\n",
    "data.groupby(['Year'])['Salary']\n",
    "\n",
    "# display the average salary per year\n",
    "data.groupby(['Year'])['Salary'].mean()\n",
    "\n",
    "# display the total salary each employee received in all the years they worked for the company\n",
    "data.groupby(['Name'])['Salary'].sum()\n",
    "\n",
    "# group the data by Year and by Department\n",
    "data.groupby(['Year', 'Department'])['Salary'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# Replace Values\n",
    "s = pd.Series(['cat', 'dog', np.nan, 'rabbit'])\n",
    "s.map({'cat': 'kitten', 'dog': 'puppy'})\n",
    "# another e.g.\n",
    "df['label'] = df['label'].map({'ham':0,'spam':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in a file from local computer or directly from a URL\n",
    "\n",
    "# various file formats that can be read in out wrote out\n",
    "'''\n",
    "Format Type     Data Description      Reader           Writer\n",
    "text                  CSV            read_csv          to_csv\n",
    "text                 JSON            read_json         to_json\n",
    "text                 HTML            read_html         to_html\n",
    "text             Local clipboard  read_clipboard     to_clipboard\n",
    "binary             MS Excel          read_excel        to_excel\n",
    "binary            HDF5 Format        read_hdf           to_hdf\n",
    "binary           Feather Format     read_feather      to_feather\n",
    "binary              Msgpack         read_msgpack      to_msgpack\n",
    "binary               Stata           read_stata        to_stata\n",
    "binary                SAS             read_sas \n",
    "binary        Python Pickle Format   read_pickle       to_pickle\n",
    "SQL                   SQL             read_sql          to_sql\n",
    "SQL             Google Big Query      read_gbq          to_gbq\n",
    "'''\n",
    "\n",
    "# to read about different types of files, and further functionality of reading in files, visit: http://pandas.pydata.org/pandas-docs/version/0.20/io.html\n",
    "df = pd.read_csv('local_path/file.csv')\n",
    "df = pd.read_csv('https://file_path/file.csv')\n",
    "\n",
    "# when reading in tables, can specify separators, and note a column to be used as index separators can include tabs (“\\t”), commas(“,”), pipes (“|”), etc.\n",
    "df = pd.read_table('https://file_path/file', sep='|', index_col='column_x')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the df data\n",
    "df           \n",
    "# print the first 30 and last 30 rows\n",
    "type(df)     \n",
    "# DataFrame\n",
    "df.head()    \n",
    "# print the first 5 rows\n",
    "df.head(10)  \n",
    "# print the first 10 rows\n",
    "df.tail()    \n",
    "# print the last 5 rows\n",
    "df.index     \n",
    "# “the index” (aka “the labels”)\n",
    "df.columns   \n",
    "# column names (which is “an index”)\n",
    "df.dtypes    \n",
    "# data types of each column\n",
    "df.shape\n",
    "# display only the number of rows\n",
    "df.shape[0]\n",
    "# number of rows and columns\n",
    "df.values    \n",
    "# underlying numpy array — df are stored as numpy arrays for effeciencies.\n",
    "\n",
    "# summarize (describe) the DataFrame\n",
    "# describe all numeric columns\n",
    "df.describe()\n",
    "\n",
    "# describe all object columns\n",
    "df.describe(include=['object'])\n",
    "\n",
    "# describe all columns\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# select a column\n",
    "df['column_y']         \n",
    "# select one column\n",
    "type(df['column_y'])   \n",
    "# determine datatype of column (e.g., Series)\n",
    "df.column_y            \n",
    "# select one column using the DataFrame attribute — not effective if column names have spaces\n",
    "\n",
    "# summarize a Series/column\n",
    "df.column_y.describe()   \n",
    "# describe a single column\n",
    "df.column_z.mean()       \n",
    "# only calculate the mean\n",
    "df[“column_z”].mean()    \n",
    "# alternate method for calculating mean\n",
    "\n",
    "# count the number of occurrences of each value\n",
    "df.column_y.value_counts()   \n",
    "# most useful for categorical variables, but can also be used with numeric variables\n",
    "\n",
    "# filter df by one column, and print out values of another column\n",
    "# when using numeric values, no quotations\n",
    "df[df.column_y == “string_value”].column_z\n",
    "df[df.column_y == 20 ].column_z    \n",
    " \n",
    "# display the 3 most frequent occurances of column in ‘df’\n",
    "df.column_y.value_counts()[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering and Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# boolean filtering: only show df with column_z < 20\n",
    "filter_bool = df.column_z < 20    \n",
    "# create a Series of booleans…\n",
    "df[filter_bool]                \n",
    "# …and use that Series to filter rows\n",
    "df[filter_bool].describe()     \n",
    "# describes a data frame filtered by filter_bool\n",
    "df[df.column_z < 20]           \n",
    "# or, combine into a single step\n",
    "df[df.column_z < 20].column_x  \n",
    "# select one column from the filtered results\n",
    "df[df[“column_z”] < 20].column_x     \n",
    "# alternate method \n",
    "df[df.column_z < 20].column_x.value_counts()   \n",
    "# value_counts of resulting Series, can also use .mean(), etc. instead of .value_counts()\n",
    "\n",
    "# boolean filtering with multiple conditions; indexes are in square brackets, conditions are in parens\n",
    "df[(df.column_z < 20) & (df.column_y==’string’)] \n",
    "# ampersand for AND condition \n",
    "df[(df.column_z < 20) | (df.column_z > 60)] \n",
    "# pipe for OR condition\n",
    "\n",
    "# can also filter df using pandas.Series.isin \n",
    "df[df.column_x.isin([“string_1”, “string_2”])]\n",
    "\n",
    "# display a cross-tabulation of two Series\n",
    "pd.crosstab(df.column_x, df.column_y)\n",
    "\n",
    "# alternative syntax for boolean filtering (noted as “experimental” in the documentation)\n",
    "df.query('column_z < 20') \n",
    "# df[df.column_z < 20]\n",
    "df.query(\"column_z < 20 and column_y=='string'\")  \n",
    "# df[(df.column_z < 20) & (df.column_y==’string’)]\n",
    "df.query('column_z < 20 or column_z > 60')        \n",
    "# df[(df.column_z < 20) | (df.column_z > 60)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# sorting\n",
    "df.column_z.order()          \n",
    "# sort a column\n",
    "df.sort_values(‘column_z’)   \n",
    "# sort a DataFrame by a single column\n",
    "df.sort_values(‘column_z’, ascending=False)     \n",
    "# use descending order instead\n",
    "\n",
    "# Sort dataframe by multiple columns\n",
    "df = df.sort([‘col1’,’col2',’col3'],ascending=[1,1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Multiple Columns and Filtering Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# select multiple columns\n",
    "my_cols = [‘column_x’, ‘column_y’]  \n",
    "# create a list of column names…\n",
    "df[my_cols]                   \n",
    "# …and use that list to select columns\n",
    "df[[‘column_x’, ‘column_y’]]  \n",
    "# or, combine into a single step — double brackets due to indexing a list.\n",
    "\n",
    "# use loc to select columns by name\n",
    "df.loc[:, ‘column_x’]    \n",
    "# colon means “all rows”, then select one column\n",
    "df.loc[:, [‘column_x’, ‘column_y’]]  \n",
    "# select two columns\n",
    "df.loc[:, ‘column_x’:’column_y’]     \n",
    "# select a range of columns (i.e., selects all columns including first through last specified)\n",
    "\n",
    "# loc can also filter rows by “name” (the index)\n",
    "df.loc[0, :]       \n",
    "# row 0, all columns\n",
    "df.loc[0:2, :]     \n",
    "# rows 0/1/2, all columns\n",
    "df.loc[0:2, ‘column_x’:’column_y’] \n",
    "# rows 0/1/2, range of columns\n",
    "\n",
    "# use iloc to filter rows and select columns by integer position\n",
    "df.iloc[:, [0, 3]]     \n",
    "# all rows, columns in position 0/3\n",
    "df.iloc[:, 0:4]        \n",
    "# all rows, columns in position 0/1/2/3\n",
    "df.iloc[0:3, :]        \n",
    "# rows in position 0/1/2, all columns\n",
    "\n",
    "#filtering out and dropping rows based on condition (e.g., where column_x values are null)\n",
    "drop_rows = df[df[“column_x”].isnull()]\n",
    "new_df = df[~df.isin(drop_rows)].dropna(how=’all’)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming, Adding, and Removing Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# rename one or more columns\n",
    "df.rename(columns={‘original_column_1’:’column_x’, ‘original_column_2’:’column_y’}, inplace=True) \n",
    "# saves changes \n",
    "\n",
    "# replace all column names (in place)\n",
    "new_cols = [‘column_x’, ‘column_y’, ‘column_z’]\n",
    "df.columns = new_cols\n",
    "\n",
    "# replace all column names when reading the file\n",
    "df = pd.read_csv(‘df.csv’, header=0, names=new_cols)\n",
    "\n",
    "# add a new column as a function of existing columns\n",
    "df[‘new_column_1’] = df.column_x + df.column_y\n",
    "df[‘new_column_2’] = df.column_x * 1000   \n",
    "#can create new columns without for loops\n",
    "\n",
    "# removing columns\n",
    "df.drop(‘column_x’, axis=1)   \n",
    "# axis=0 for rows, 1 for columns — does not drop in place\n",
    "df.drop([‘column_x’, ‘column_y’], axis=1, inplace=True) \n",
    "# drop multiple columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lower-case all DataFrame column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# Lower-case all DataFrame column names\n",
    "df.columns = map(str.lower, df.columns)\n",
    "\n",
    "# Even more fancy DataFrame column re-naming\n",
    "# lower-case all DataFrame column names (for example)\n",
    "df.rename(columns=lambda x: x.split('.')[-1], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# missing values are usually excluded by default\n",
    "df.column_x.value_counts()             \n",
    "# excludes missing values\n",
    "\n",
    "df.column_x.value_counts(dropna=False) \n",
    "# includes missing values\n",
    "\n",
    "# find missing values in a Series\n",
    "df.column_x.isnull()  \n",
    "# True if missing\n",
    "\n",
    "df.column_x.notnull() \n",
    "# True if not missing\n",
    "\n",
    "# use a boolean Series to filter DataFrame rows\n",
    "df[df.column_x.isnull()]  \n",
    "# only show rows where column_x is missing\n",
    "\n",
    "df[df.column_x.notnull()] \n",
    "# only show rows where column_x is not missing\n",
    "\n",
    "# understanding axes\n",
    "df.sum()       \n",
    "# sums “down” the 0 axis (rows)\n",
    "\n",
    "df.sum(axis=0) \n",
    "# equivalent (since axis=0 is the default)\n",
    "\n",
    "df.sum(axis=1) \n",
    "# sums “across” the 1 axis (columns)\n",
    "\n",
    "# adding booleans\n",
    "pd.Series([True, False, True])       \n",
    "# create a boolean Series\n",
    "pd.Series([True, False, True]).sum() \n",
    "# converts False to 0 and True to 1\n",
    "\n",
    "# find missing values in a DataFrame\n",
    "df.isnull() \n",
    "# DataFrame of booleans\n",
    "df.isnull().sum() \n",
    "# count the missing values in each column\n",
    "\n",
    "# drop missing values\n",
    "df.dropna(inplace=True)   \n",
    "# drop a row if ANY values are missing, defaults to rows, but can be applied to columns with axis=1\n",
    "df.dropna(how=’all’, inplace=True)  \n",
    "# drop a row only if ALL values are missing\n",
    "\n",
    "# fill in missing values\n",
    "df.column_x.fillna(value=’NA’, inplace=True) \n",
    "\n",
    "# fill in missing values with ‘NA’\n",
    "# value does not have to equal a string — can be set as some calculated value like df.column_x.mode(), or just a number like 0 \n",
    "\n",
    "# turn off the missing value filter\n",
    "df = pd.read_csv(‘df.csv’, header=0, names=new_cols, na_filter=False)\n",
    "\n",
    "# Clean up missing values in multiple DataFrame columns\n",
    "df = df.fillna({\n",
    " ‘col1’: ‘missing’,\n",
    " ‘col2’: ‘99.999’,\n",
    " ‘col3’: ‘999’,\n",
    " ‘col4’: ‘missing’,\n",
    " ‘col5’: ‘missing’,\n",
    " ‘col6’: ‘99’\n",
    "})\n",
    "\n",
    "# Concatenate two DataFrame columns into a new, single column - (useful when dealing with composite keys, for example)\n",
    "df[‘newcol’] = df[‘col1’].map(str) + df[‘col2’].map(str)\n",
    "\n",
    "# Doing calculations with DataFrame columns that have missing values\n",
    "\n",
    "# In example below, swap in 0 for df[‘col1’] cells that contain null\n",
    "df[‘new_col’] = np.where(pd.isnull(df[‘col1’]),0,df[‘col1’]) + df[‘col2’]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Duplicated Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# detecting duplicate rows\n",
    "df.duplicated()\n",
    "\n",
    "# True if a row is identical to a previous row\n",
    "df.duplicated().sum()\n",
    "\n",
    "# count of duplicates\n",
    "df[df.duplicated()]\n",
    "\n",
    "# only show duplicates\n",
    "df.drop_duplicates()\n",
    "\n",
    "# drop duplicate rows\n",
    "df.column_z.duplicated()\n",
    "\n",
    "# check a single column for duplicates\n",
    "df.duplicated([‘column_x’, ‘column_y’, ‘column_z’]).sum()  \n",
    "# specify columns for finding duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split-Apply-Combine\n",
    "<img src=\"http://i.imgur.com/yjNkiwL.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# for each value in column_x, calculate the mean column_y \n",
    "df.groupby(‘column_x’).column_y.mean()\n",
    "\n",
    "# for each value in column_x, count the number of occurrences\n",
    "df.column_x.value_counts()\n",
    "\n",
    "# for each value in column_x, describe column_y\n",
    "df.groupby(‘column_x’).column_y.describe()\n",
    "\n",
    "# similar, but outputs a DataFrame and can be customized\n",
    "df.groupby(‘column_x’).column_y.agg([‘count’, ‘mean’, ‘min’, ‘max’])\n",
    "df.groupby(‘column_x’).column_y.agg([‘count’, ‘mean’, ‘min’, ‘max’]).sort_values(‘mean’)\n",
    "\n",
    "# if you don’t specify a column to which the aggregation function should be applied, it will be applied to all numeric columns\n",
    "df.groupby(‘column_x’).mean()\n",
    "df.groupby(‘column_x’).describe()\n",
    "\n",
    "# can also groupby a list of columns, i.e., for each combination of column_x and column_y, calculate the mean column_z\n",
    "df.groupby([“column_x”,”column_y”]).column_z.mean()\n",
    "\n",
    "#to take groupby results out of hierarchical index format (e.g., present as table), use .unstack() method\n",
    "df.groupby(“column_x”).column_y.value_counts().unstack()\n",
    "\n",
    "#conversely, if you want to transform a table into a hierarchical index, use the .stack() method\n",
    "df.stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging and Concatenating Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "#concatenating two dfs together (just smooshes them together, does not pair them in any meaningful way) - axis=1 concats df2 to right side of df1; axis=0 concats df2 to bottom of df1\n",
    "new_df = pd.concat([df1, df2], axis=1)\n",
    "\n",
    "#merging dfs based on paired columns; columns do not need to have same name, but should match values; left_on column comes from df1, right_on column comes from df2\n",
    "new_df = pd.merge(df1, df2, left_on=’column_x’, right_on=’column_y’)\n",
    "\n",
    "#can also merge slices of dfs together, though slices need to include columns used for merging\n",
    "new_df = pd.merge(df1[[‘column_x1’, ‘column_x2’]], df2, left_on=’column_x2', right_on=’column_y’)\n",
    "\n",
    "#merging two dataframes based on shared index values (left is df1, right is df2)\n",
    "new_df = pd.merge(df1, df2, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequently Used Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### map existing values to a different set of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "df[‘column_x’] = df.column_y.map({‘F’:0, ‘M’:1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### encode strings as integer values (automatically starts at 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "df[‘column_x_num’] = df.column_x.factorize()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### determine unique values in a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "df.column_x.nunique() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### count the number of unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "df.column_x.unique()    \n",
    "# returns the unique values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### replace all instances of a value in a column (must match entire value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "df.column_y.replace(‘old_string’, ‘new_string’, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### alter values in one column based on values in another column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# changes occur in place\n",
    "# can use either .loc or .ix methods\n",
    "df.loc[df[“column_x”] == 5, “column_y”] = 1\n",
    "df.ix[df.column_x == “string_value”, “column_y”] = “new_string_value”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### transpose data frame (i.e. rows become columns, columns become rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### string methods are accessed via ‘str’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "df.column_y.str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### converts to uppercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "df.column_y.str.contains(‘value’, na=’False’) \n",
    "# checks for a substring, returns boolean series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### convert a string to the datetime_column format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "df[‘time_column’] = pd.to_datetime_column(df.time_column)\n",
    "df.time_column.dt.hour "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### datetime_column format exposes convenient attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "(df.time_column.max() — df.time_column.min()).days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### boolean filtering with datetime_column format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "df[df.time_column > pd.datetime_column(2014, 1, 1)]   \n",
    "# also allows you to do datetime_column “math”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### setting and then removing an index, resetting index can help remove hierarchical indexes while preserving the table in its basic structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "df.set_index(‘time_column’, inplace=True)\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sort a column by its index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "df.column_y.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### change the data type of a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "df[‘column_x’] = df.column_x.astype(‘float’)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### change the data type of a column when reading in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "pd.read_csv(‘df.csv’, dtype={‘column_x’:float})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create dummy variables for ‘column_x’ and exclude first dummy column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "column_x_dummies = pd.get_dummies(df.column_x).iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### concatenate two DataFrames (axis=0 for rows, axis=1 for columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df, column_x_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop through rows in a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# Loop through rows in a DataFrame\n",
    "for index, row in df.iterrows():\n",
    " print index, row[‘column_x’]\n",
    "\n",
    "# Much faster way to loop through DataFrame rows if you can work with tuples\n",
    "for row in df.itertuples():\n",
    " print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get rid of non-numeric values throughout a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "for col in df.columns.values:\n",
    " df[col] = df[col].replace(‘[⁰-9]+.-’, ‘’, regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change all NaNs to None (useful before loading to a db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "df = df.where((pd.notnull(df)), None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split delimited values in a DataFrame column into two new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "df['new_col1'], df['new_col2'] = zip(*df['original_col'].apply(lambda x: x.split(': ', 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collapse hierarchical column indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "df.columns = df.columns.get_level_values(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### change a Series to the ‘category’ data type (reduces memory usage and increases performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "df[‘column_y’] = df.column_y.astype(‘category’)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### temporarily define a new column as a function of existing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "df.assign(new_column = df.column_x + df.spirit + df.column_y)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
